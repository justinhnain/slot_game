---
title: "Altar of the God of Chaos"
format: html
editor: visual
theme: darkly
---

```{r}
#| output: false
#| 
{
  library(tidyverse)  #useful dataframe functions for R
  library(infer)      #statistical inference libraries
  library(reticulate) #allows Python and R interoperability
}
```

```{python}
import random, itertools
import pandas as pd
```

## Define a 3-reel 1-line game

```{python}
#elements that reels 1 to 3 can assume
N1 = 10
N2 = 11
N3 = 5

#reels 1 to 3
x1 = list(range(1, N1 + 1))
x2 = list(range(1, N2 + 1))
x3 = list(range(1, N3 + 1))

num_combinations = N1 * N2 * N3
combinations= list(itertools.product(x1, x2, x3))
```

We define the set of all outcomes to be a combination of ordered triples to be $\Omega$, equal to the set of all $(x_1, x_2, x_3) \in \{x,y,z \in \mathbb{N}^3 : 1 \leq x \leq 10, 1 \leq y \leq 11, 1 \leq z \leq 5\}$\

### Include a bonus round for when the second reel is "11" and the first reel is odd

In other words, if $x_2 = 11$ and $x_1 \equiv 1\text{ (mod 2)}$ then the payout becomes an outcome of the discrete random variable $X$ with the following payout table, for which $E[q(X)] = 20$:

```{python}
#| code-fold: true
#| code-summary: "Show the code"
from IPython.display import Markdown
from tabulate import tabulate
table = [
         ["p(x)","1/6","1/6","1/6","1/6","1/6","1/6"],
         ["q(x)",15, 15, 15, 15, 30, 30],
         ]
Markdown(tabulate(
  table, 
  headers=["X", "1", "2", "3", "4", "5", "6"]
))

```

```{python}
lower_wins = [1, 2, 3, 4]
upper_wins = [5, 6]

lower_payout = 15
upper_payout = 30

def bonus_roll():
  roll = random.randint(1,6)
  if (roll in lower_wins):
    return lower_payout
  else:
    return upper_payout
  
#expected value must be $20
```

### Define the payout matrix and winning combos

We define the set of winning combinations $W \subset \Omega$ to be equal to $\{(x,y,z) \in \Omega: (y = 11\land x \equiv\text{1 (mod 2)}) \lor (x,y) \in \{(5,5), (1,1), (2,2)\}\lor x=y=z\}$ and the payout function $$f: W \rightarrow \mathbb{R}$$ such that

$$
f(w) = 
\begin{cases}
  1, & \text{if } w = (5,5,x_3) \\
  1, & \text{if } w = (2,2,x_3) \\
1, & \text{if } w = (1,1,x_3) \\
3, & \text{if } w\text{'s coordinates are all equal}  \\
x \in X, & \text{if } w = (x_1, 11, x_3)\text{ and }x_1 \equiv 1\text{ (mod 2)}
\end{cases}
$$

```{python}
#| output: false
#winning combos & payouts
wins = {
  # (5, 5) : 1,
  # (1, 1) : 1,
  # (2, 2) : 1
  # (x odd, 11, y) : bonus_roll() with expected payout 20,
  # (x, y, z) : 3 when x = y = z
}


centre_11_win = list(filter((lambda combo : combo[1] == 11 and combo[0] % 2 == 1), combinations))
all_equal_win = list(filter(lambda combo: combo[0] == combo[1] == combo[2], combinations))

def leading_double(num, combo):
  return num == combo[0] == combo[1] != combo[2] #exclude triples
  
manual_5_wins = list(filter(lambda combo : leading_double(5, combo), combinations))
manual_2_wins = list(filter(lambda combo : leading_double(2, combo), combinations))
manual_1_wins = list(filter(lambda combo : leading_double(1, combo), combinations))

```

### Build the payout matrix

In other words, we populate $f$, where $f$ is defined by `wins`. Building `wins` as a dictionary makes `wins` easy to test, because discrete outcomes allow us to establish a bijection between `wins` and the intended payout function called $f$.

```{python}
#| output: false
#add payout combos to win dictionary
[wins.update({win: bonus_roll}) for win in centre_11_win]
[wins.update({win: 3}) for win in all_equal_win] #add payouts for x = y = z case
[wins.update({win: 1}) for win in manual_5_wins]
[wins.update({win: 1}) for win in manual_2_wins]
[wins.update({win: 1}) for win in manual_1_wins]
```

### Test, test, test!

More rigorous testing ought to be done, but this captures some potential high level errors.

```{python}
#tests
assert num_combinations == len(combinations), "the number of combinations is incorrect"
assert len(centre_11_win) == N1 / 2 * N3, "the number of bonus rounds is incorrect"
assert len(all_equal_win) == min(N1, N2, N3), "the number of equal rounds is incorrect"
assert len(manual_5_wins) == 4, "the number of (5, 5, x) tuples is incorrect"
assert len(manual_2_wins) == 4, "the number of (2, 2, x) tuples is incorrect"
assert len(manual_1_wins) == 4, "the number of (1, 1, x) tuples is incorrect"

assert len(wins) == len(centre_11_win) + len(all_equal_win) + len(manual_5_wins) + len(manual_2_wins) + len(manual_1_wins), "number of winning combos is incorrect"

assert lower_payout * (len(lower_wins) / len(lower_wins + upper_wins)) + upper_payout * len(upper_wins) / len(lower_wins + upper_wins) == 20, "bonus roll expected payout isn't $20"


total_payout = 0
for i in all_equal_win + manual_5_wins + manual_2_wins + manual_1_wins:
  total_payout += wins[i]
for k in centre_11_win:
  total_payout += 20 #expected value of bonus rounds
  
expected_value = total_payout / num_combinations

assert expected_value < 1, f"your payout of {expected_value} favours the player!"
print(expected_value)
```

## Simulate a 3-reel 1-line game

We begin by constructing a dataframe with all possible combinations of outcomes, corresponding to $\Omega$.

```{r}
sample_space <- expand.grid(py$x1, py$x2, py$x3) |> 
  as_tibble()
sample_space <- sample_space |> 
  rename(
    reel_1 = Var1, 
    reel_2 = Var2, 
    reel_3 = Var3
  )
```

Followed by constructing the dataframe `win_df` of winning combinations $W \subset \Omega$.

```{python}
win_keys = list(wins.keys())
win_df = pd.DataFrame(win_keys)
```

```{r}
win_df <- py$win_df |> 
  as_tibble() |> 
  rename(reel_1 = "0", reel_2 = "1", reel_3 = "2")
```

Then, we simulate `outcome`s from $N_{spins}$ spins across $N_{sessions}$ sessions by sampling from the sample space $\Omega\text{'s}$ dataframe, with replacement.

```{r}
#| output: false
N_spins <- 10
N_sessions <- 10000

outcome <- sample_space |>
  rep_sample_n(size = N_spins, replace = TRUE, reps = N_sessions) |> 
  mutate(replicate = as_factor(replicate)) |> 
  semi_join(win_df, by = join_by(reel_1, reel_2, reel_3)) ## identifies all hits.

outcome <- outcome |> 
  rowwise() |> ##prevents recycling of bonus_roll
  mutate(
    payout = ifelse(
      reel_2 == 11, 
      py$bonus_roll(),
      py$wins[str_glue("({reel_1}, {reel_2}, {reel_3})")][[1]]
    )
  ) |> 
  group_by(replicate) |> 
  summarise(payout = sum(payout) / 10)
        
outcome <- outcome |> #fills missing games with 0 payouts
  complete(replicate) |> 
  mutate(
    payout = if_else(is.na(payout), 0, payout)
  )
```

### Explore the payouts in the play sessions

This plot seems reasonably in line with the mathematical model's intended payout, which states that for each dollar spent, the house exacts a toll of about \$0.04. However, it's best to examine this more rigorously.

```{r}
#| code-fold: show
#| code-summary: "Hide the code"
outcome |> 
  ggplot(aes(payout * 10)) + #total earned rather than earning per dollar.
  geom_density(
    bw = 8.5, ##heavy smoothing because of the discrete volatility of the data.
    fill = "skyblue"
  ) + 
  labs(
    subtitle = "A fair number of players saw earnings as much as 5x what they spent",
    y = "Percentage", 
    x = "Payout (earned after $10 spent per player)",
  ) +
    ggtitle(latex2exp::TeX("The plot adheres to the theoretical payout of $\\$6.65 \\approx \\$10 \\times 0.96^{10}$")) +
  scale_x_continuous(
    breaks = scales::breaks_extended(n = 7),
    labels = scales::label_dollar()
  ) +
  scale_y_continuous(
    breaks = scales::breaks_extended(n = 7),
    labels = scales::label_percent()
  ) +
  theme_minimal()
```

### Statistically verify the simulation's expected payout

We begin by constructing a long-run play session with 1,000,000 pulls of the lever.

```{r}
#| output: false
set.seed(11334) #reproducibility
N_samples = 10^6

longrun_spins <- slice_sample(sample_space, n = N_samples, replace = TRUE)

losing_spins <- longrun_spins |> 
  anti_join(win_df) |> 
  mutate(payout = 0)

winning_spins <- longrun_spins |> 
  semi_join(win_df) |> 
  rowwise() |> 
  mutate(
    payout = ifelse(
      reel_2 == 11, 
      py$bonus_roll(),
      py$wins[str_glue("({reel_1}, {reel_2}, {reel_3})")][[1]]
    )
  )

longrun_spins <- bind_rows(winning_spins, losing_spins) |> 
  ungroup()
```

These data are quite zero-inflated, but the number 30 isn't too terribly extreme, and t procedures are quite robust (especially with this sample size).

```{r}
#| code-fold: true
#| code-summary: "Show the code"
p1 <- ggplot(longrun_spins, aes(payout)) +
  geom_histogram(
    binwidth = 1,
    colour = "white",
    fill = "skyblue"
  ) +
  xlab("Payout per game") +
  ylab("") +
  theme_minimal()
p1
```

A 95% t-confidence interval for the payout per game is $0.952729 \pm 0.0086579$, which captures the theoretical expected payout of approximately $0.958$.

```{r}
t_test(longrun_spins, response = payout)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
lr_mean <- mean(longrun_spins$payout)
lr_se <- sd(longrun_spins$payout)/sqrt(N_samples)
openintro::normTail(m = lr_mean, s = lr_se, M = c(qnorm(0.025, mean = lr_mean, sd = lr_se), qnorm(0.975, mean = lr_mean, sd = lr_se)), col = "skyblue")
```

### Cross-reference the result

Even though t procedures are robust to violations of assumptions, it's best to double check any results from them. We proceed by cross-referencing with a method that requires less assumptions than t-based procedures: the **non-parametric bootstrap**.

We randomly sample $N_{sample}$ observations before resampling from the sample.

```{r}
set.seed(12347) #reproducibility
N_sample <- 10000

subset_spins <- longrun_spins |>
  slice_sample(n = N_sample)

obs_stat <- mean(subset_spins$payout)
```

This is done with the help of the tidymodels statistical inference framework.

```{r}
set.seed(12347) #reproducibility
bootstrap_stats <- specify(subset_spins, response = payout) |> 
  generate(
    reps = N_sample, 
    type = "bootstrap"
  ) |> 
  calculate(stat = "mean")

bootstrap_95_percentile_interval <- bootstrap_stats |> 
  get_confidence_interval(
    point_estimate = obs_stat,
    level = 0.95
  )
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
bootstrap_stats |> 
  visualize(fill = "skyblue") +
  shade_confidence_interval(bootstrap_95_percentile_interval, linetype = "dashed", size = 0.5) +
  geom_vline(xintercept = obs_stat, linetype = "dotted", colour = "red") +
  theme_minimal() +
  labs(
    x = "", 
    y = "",
    title = "The 95% bootstrap percentile interval also captures the theoretical payout",
    subtitle = "The interval is a quite wide because the samples are 100x smaller than the original"
  ) +
  scale_y_continuous(labels = NULL) +
  annotate(
    geom = "text",
    label = str_glue("Mean of \n {obs_stat}"),
    x = obs_stat + 0.025,
    y = 1000
  ) +
  geom_text(
    data = bootstrap_95_percentile_interval |> pivot_longer(cols = 1:2),
    aes(x = value, label = value),
    y = 1000
  )
```
